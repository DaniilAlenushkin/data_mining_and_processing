{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Загружаем необходимые библиотеки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загружаем данные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pre_data = pd.read_csv('datasets/V1.csv')\n",
    "data = pre_data.iloc [: , 1:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Формируем 4 набора данных для исследований:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем исходный набор данных:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     Email  Address  Avatar  Avg. Session Length  Time on App  \\\n0     58.0     29.0   132.0            34.497268    12.655651   \n1     93.0      8.0    25.0            31.926272    11.109461   \n2    241.0     11.0     6.0            33.000915    11.330278   \n3     73.0     43.0   114.0            34.305557    13.717514   \n4     43.0     47.0    80.0            33.330673    12.795189   \n..     ...      ...     ...                  ...          ...   \n495   40.0     54.0   127.0            33.237660    13.566160   \n496   73.0      8.0   104.0            34.702529    11.695736   \n497   93.0     52.0    18.0            32.646777    11.499409   \n498   93.0     53.0   128.0            33.322501    12.391423   \n499   44.0     45.0    27.0            33.715981    12.418808   \n\n     Length of Membership  Yearly Amount Spent  \n0                4.082621           587.951054  \n1                2.664034           392.204933  \n2                4.104543           487.547505  \n3                3.120179           581.852344  \n4                4.446308           599.406092  \n..                    ...                  ...  \n495              3.746573           573.847438  \n496              3.576526           529.049004  \n497              4.958264           551.620145  \n498              2.336485           456.469510  \n499              2.735160           497.778642  \n\n[500 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Email</th>\n      <th>Address</th>\n      <th>Avatar</th>\n      <th>Avg. Session Length</th>\n      <th>Time on App</th>\n      <th>Length of Membership</th>\n      <th>Yearly Amount Spent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>58.0</td>\n      <td>29.0</td>\n      <td>132.0</td>\n      <td>34.497268</td>\n      <td>12.655651</td>\n      <td>4.082621</td>\n      <td>587.951054</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>93.0</td>\n      <td>8.0</td>\n      <td>25.0</td>\n      <td>31.926272</td>\n      <td>11.109461</td>\n      <td>2.664034</td>\n      <td>392.204933</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>241.0</td>\n      <td>11.0</td>\n      <td>6.0</td>\n      <td>33.000915</td>\n      <td>11.330278</td>\n      <td>4.104543</td>\n      <td>487.547505</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>73.0</td>\n      <td>43.0</td>\n      <td>114.0</td>\n      <td>34.305557</td>\n      <td>13.717514</td>\n      <td>3.120179</td>\n      <td>581.852344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43.0</td>\n      <td>47.0</td>\n      <td>80.0</td>\n      <td>33.330673</td>\n      <td>12.795189</td>\n      <td>4.446308</td>\n      <td>599.406092</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>40.0</td>\n      <td>54.0</td>\n      <td>127.0</td>\n      <td>33.237660</td>\n      <td>13.566160</td>\n      <td>3.746573</td>\n      <td>573.847438</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>73.0</td>\n      <td>8.0</td>\n      <td>104.0</td>\n      <td>34.702529</td>\n      <td>11.695736</td>\n      <td>3.576526</td>\n      <td>529.049004</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>93.0</td>\n      <td>52.0</td>\n      <td>18.0</td>\n      <td>32.646777</td>\n      <td>11.499409</td>\n      <td>4.958264</td>\n      <td>551.620145</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>93.0</td>\n      <td>53.0</td>\n      <td>128.0</td>\n      <td>33.322501</td>\n      <td>12.391423</td>\n      <td>2.336485</td>\n      <td>456.469510</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>44.0</td>\n      <td>45.0</td>\n      <td>27.0</td>\n      <td>33.715981</td>\n      <td>12.418808</td>\n      <td>2.735160</td>\n      <td>497.778642</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sub_data = data.copy()\n",
    "data_address = [i.split()[-2] for i in data['Address']]\n",
    "data_email = [i.split('@')[-1] for i in data['Email']]\n",
    "original_sub_data['Address'] = data_address\n",
    "original_sub_data['Email'] = data_email\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "avatar_encoded = ordinal_encoder.fit_transform(original_sub_data['Avatar'].values.reshape(-1,1))\n",
    "address_encoded = ordinal_encoder.fit_transform(original_sub_data['Address'].values.reshape(-1,1))\n",
    "email_encoded = ordinal_encoder.fit_transform(original_sub_data['Email'].values.reshape(-1,1))\n",
    "original_sub_data['Avatar'] = avatar_encoded\n",
    "original_sub_data['Address'] = address_encoded\n",
    "original_sub_data['Email'] = email_encoded\n",
    "original_data = original_sub_data.drop('Time on Website', axis=1)\n",
    "original_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем преобразованный набор исходных данных:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5         6\n0    0.238683  0.475410  0.963504  0.751425  0.626620  0.573101  0.651040\n1    0.382716  0.131148  0.182482  0.362306  0.393016  0.359869  0.266355\n2    0.991770  0.180328  0.043796  0.524953  0.426378  0.576396  0.453725\n3    0.300412  0.704918  0.832117  0.722409  0.787050  0.428434  0.639055\n4    0.176955  0.770492  0.583942  0.574861  0.647702  0.627768  0.673552\n..        ...       ...       ...       ...       ...       ...       ...\n495  0.164609  0.885246  0.927007  0.560784  0.764183  0.522589  0.623324\n496  0.300412  0.131148  0.759124  0.782491  0.481592  0.497028  0.535285\n497  0.382716  0.852459  0.131387  0.471354  0.451931  0.704722  0.579642\n498  0.382716  0.868852  0.934307  0.573625  0.586699  0.310634  0.392650\n499  0.181070  0.737705  0.197080  0.633178  0.590837  0.370560  0.473831\n\n[500 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.238683</td>\n      <td>0.475410</td>\n      <td>0.963504</td>\n      <td>0.751425</td>\n      <td>0.626620</td>\n      <td>0.573101</td>\n      <td>0.651040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.382716</td>\n      <td>0.131148</td>\n      <td>0.182482</td>\n      <td>0.362306</td>\n      <td>0.393016</td>\n      <td>0.359869</td>\n      <td>0.266355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.991770</td>\n      <td>0.180328</td>\n      <td>0.043796</td>\n      <td>0.524953</td>\n      <td>0.426378</td>\n      <td>0.576396</td>\n      <td>0.453725</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.300412</td>\n      <td>0.704918</td>\n      <td>0.832117</td>\n      <td>0.722409</td>\n      <td>0.787050</td>\n      <td>0.428434</td>\n      <td>0.639055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.176955</td>\n      <td>0.770492</td>\n      <td>0.583942</td>\n      <td>0.574861</td>\n      <td>0.647702</td>\n      <td>0.627768</td>\n      <td>0.673552</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0.164609</td>\n      <td>0.885246</td>\n      <td>0.927007</td>\n      <td>0.560784</td>\n      <td>0.764183</td>\n      <td>0.522589</td>\n      <td>0.623324</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0.300412</td>\n      <td>0.131148</td>\n      <td>0.759124</td>\n      <td>0.782491</td>\n      <td>0.481592</td>\n      <td>0.497028</td>\n      <td>0.535285</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0.382716</td>\n      <td>0.852459</td>\n      <td>0.131387</td>\n      <td>0.471354</td>\n      <td>0.451931</td>\n      <td>0.704722</td>\n      <td>0.579642</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0.382716</td>\n      <td>0.868852</td>\n      <td>0.934307</td>\n      <td>0.573625</td>\n      <td>0.586699</td>\n      <td>0.310634</td>\n      <td>0.392650</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0.181070</td>\n      <td>0.737705</td>\n      <td>0.197080</td>\n      <td>0.633178</td>\n      <td>0.590837</td>\n      <td>0.370560</td>\n      <td>0.473831</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "original_rescaled_data = pd.DataFrame(scaler.fit_transform(original_data))\n",
    "original_rescaled_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем исходный набор данных из существенных признаков:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     Time on App  Length of Membership  Yearly Amount Spent\n0      12.655651              4.082621           587.951054\n1      11.109461              2.664034           392.204933\n2      11.330278              4.104543           487.547505\n3      13.717514              3.120179           581.852344\n4      12.795189              4.446308           599.406092\n..           ...                   ...                  ...\n495    13.566160              3.746573           573.847438\n496    11.695736              3.576526           529.049004\n497    11.499409              4.958264           551.620145\n498    12.391423              2.336485           456.469510\n499    12.418808              2.735160           497.778642\n\n[500 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time on App</th>\n      <th>Length of Membership</th>\n      <th>Yearly Amount Spent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.655651</td>\n      <td>4.082621</td>\n      <td>587.951054</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11.109461</td>\n      <td>2.664034</td>\n      <td>392.204933</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.330278</td>\n      <td>4.104543</td>\n      <td>487.547505</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13.717514</td>\n      <td>3.120179</td>\n      <td>581.852344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.795189</td>\n      <td>4.446308</td>\n      <td>599.406092</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>13.566160</td>\n      <td>3.746573</td>\n      <td>573.847438</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>11.695736</td>\n      <td>3.576526</td>\n      <td>529.049004</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>11.499409</td>\n      <td>4.958264</td>\n      <td>551.620145</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>12.391423</td>\n      <td>2.336485</td>\n      <td>456.469510</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>12.418808</td>\n      <td>2.735160</td>\n      <td>497.778642</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essential_sub_data = data.iloc[:,4:8]\n",
    "essential_data = essential_sub_data.drop('Time on Website', axis=1)\n",
    "essential_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем преобразованный набор из исходных данных из существенных признаков:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2\n0    0.626620  0.573101  0.651040\n1    0.393016  0.359869  0.266355\n2    0.426378  0.576396  0.453725\n3    0.787050  0.428434  0.639055\n4    0.647702  0.627768  0.673552\n..        ...       ...       ...\n495  0.764183  0.522589  0.623324\n496  0.481592  0.497028  0.535285\n497  0.451931  0.704722  0.579642\n498  0.586699  0.310634  0.392650\n499  0.590837  0.370560  0.473831\n\n[500 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.626620</td>\n      <td>0.573101</td>\n      <td>0.651040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.393016</td>\n      <td>0.359869</td>\n      <td>0.266355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.426378</td>\n      <td>0.576396</td>\n      <td>0.453725</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.787050</td>\n      <td>0.428434</td>\n      <td>0.639055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.647702</td>\n      <td>0.627768</td>\n      <td>0.673552</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0.764183</td>\n      <td>0.522589</td>\n      <td>0.623324</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0.481592</td>\n      <td>0.497028</td>\n      <td>0.535285</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0.451931</td>\n      <td>0.704722</td>\n      <td>0.579642</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0.586699</td>\n      <td>0.310634</td>\n      <td>0.392650</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0.590837</td>\n      <td>0.370560</td>\n      <td>0.473831</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_essential_data = pd.DataFrame(scaler.fit_transform(essential_data))\n",
    "rescaled_essential_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделяем каждый набор данных на обучающую и тестовую выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "seed = 7\n",
    "\n",
    "original_data_X = original_data.iloc[:, :6]\n",
    "original_data_Y = original_data[\"Yearly Amount Spent\"]\n",
    "\n",
    "original_data_X_train, original_data_X_test, original_data_Y_train, original_data_Y_test = \\\n",
    "    train_test_split(original_data_X, original_data_Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "original_rescaled_data_X = original_rescaled_data.iloc[:, :6]\n",
    "original_rescaled_data_Y = original_rescaled_data[6]\n",
    "\n",
    "original_rescaled_data_X_train, original_rescaled_data_X_test, original_rescaled_data_Y_train, original_rescaled_data_Y_test = \\\n",
    "    train_test_split(original_rescaled_data_X, original_rescaled_data_Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "essential_data_X = essential_data.iloc[:, :2]\n",
    "essential_data_Y = essential_data[\"Yearly Amount Spent\"]\n",
    "\n",
    "essential_data_X_train, essential_data_X_test, essential_data_Y_train, essential_data_Y_test = \\\n",
    "    train_test_split(essential_data_X, essential_data_Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "\n",
    "rescaled_essential_data_X = rescaled_essential_data.iloc[:, :2]\n",
    "rescaled_essential_data_Y = rescaled_essential_data[2]\n",
    "\n",
    "rescaled_essential_data_X_train, rescaled_essential_data_X_test, rescaled_essential_data_Y_train, rescaled_essential_data_Y_test = \\\n",
    "    train_test_split(rescaled_essential_data_X, rescaled_essential_data_Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "datasets = [{'X_train': original_data_X_train, 'X_test': original_data_X_test, 'Y_train': original_data_Y_train,\n",
    "             'Y_test': original_data_Y_test, 'name': 'original_data'},\n",
    "            {'X_train': original_rescaled_data_X_train, 'X_test': original_rescaled_data_X_test,\n",
    "             'Y_train': original_rescaled_data_Y_train, 'Y_test': original_rescaled_data_Y_test, 'name': 'original_rescaled_data'},\n",
    "            {'X_train': essential_data_X_train, 'X_test': essential_data_X_test, 'Y_train': essential_data_Y_train,\n",
    "             'Y_test': essential_data_Y_test, 'name': 'essential_data'},\n",
    "            {'X_train': rescaled_essential_data_X_train, 'X_test': rescaled_essential_data_X_test,\n",
    "             'Y_train': rescaled_essential_data_Y_train, 'Y_test': rescaled_essential_data_Y_test, 'name': 'rescaled_essential_data'}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Определим гиперпараметры для SVR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "param_grid = {'C': [i for i in np.linspace(0.1, 10, num=10)],\n",
    "              'kernel': ['linear', 'poly']}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация SVR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameters for original_data: {'C': 10.0, 'kernel': 'linear'}\n",
      "RMSE for SVR for train original_data:  9.836194670284913\n",
      "R2_score for SVR for train original_data:  0.9846637719793999\n",
      "RMSE for SVR for test original_data:  10.047885185149736\n",
      "R2_score for SVR for test original_data:  0.9835824211779726\n",
      "\n",
      "Best hyper parameters for original_rescaled_data: {'C': 1.2000000000000002, 'kernel': 'linear'}\n",
      "RMSE for SVR for train original_rescaled_data:  0.03840738915841269\n",
      "R2_score for SVR for train original_rescaled_data:  0.9394561776023781\n",
      "RMSE for SVR for test original_rescaled_data:  0.050776377337436306\n",
      "R2_score for SVR for test original_rescaled_data:  0.8914426717617145\n",
      "\n",
      "Best hyper parameters for essential_data: {'C': 7.800000000000001, 'kernel': 'linear'}\n",
      "RMSE for SVR for train essential_data:  27.301193423611483\n",
      "R2_score for SVR for train essential_data:  0.8818516692637637\n",
      "RMSE for SVR for test essential_data:  27.13958726122749\n",
      "R2_score for SVR for test essential_data:  0.8802249779130702\n",
      "\n",
      "Best hyper parameters for rescaled_essential_data: {'C': 1.2000000000000002, 'kernel': 'linear'}\n",
      "RMSE for SVR for train rescaled_essential_data:  0.05392355757184264\n",
      "R2_score for SVR for train rescaled_essential_data:  0.8806568935404736\n",
      "RMSE for SVR for test rescaled_essential_data:  0.05490235811159831\n",
      "R2_score for SVR for test rescaled_essential_data:  0.8730836080688048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    svr_model = SVR()\n",
    "    grid_search = GridSearchCV(svr_model, param_grid)\n",
    "\n",
    "    grid_search.fit(dataset.get('X_train'), dataset.get('Y_train'))\n",
    "\n",
    "    best_params_for_data = grid_search.best_params_\n",
    "    print(f\"Best hyper parameters for {dataset.get('name')}: {best_params_for_data}\")\n",
    "\n",
    "    svr_model_train_data = SVR(C=best_params_for_data.get('C'),\n",
    "                               kernel=best_params_for_data.get('kernel'))\n",
    "    svr_model_train_data.fit(dataset.get('X_train'), dataset.get('Y_train'))\n",
    "    train_Y_pred = svr_model_train_data.predict(dataset.get('X_train'))\n",
    "    rmse_train = np.sqrt(mean_squared_error(dataset.get('Y_train'), train_Y_pred))\n",
    "    r2_train = r2_score(dataset.get('Y_train'), train_Y_pred)\n",
    "    print(f'RMSE for SVR for train {dataset.get(\"name\")}: ', rmse_train)\n",
    "    print(f'R2_score for SVR for train {dataset.get(\"name\")}: ', r2_train)\n",
    "\n",
    "    svr_model_test_data = SVR(C=best_params_for_data.get('C'),\n",
    "                              kernel=best_params_for_data.get('kernel'))\n",
    "    svr_model_test_data.fit(dataset.get('X_test'), dataset.get('Y_test'))\n",
    "    test_Y_pred = svr_model_test_data.predict(dataset.get('X_test'))\n",
    "    rmse_test = np.sqrt(mean_squared_error(dataset.get('Y_test'), test_Y_pred))\n",
    "    r2_test = r2_score(dataset.get('Y_test'), test_Y_pred)\n",
    "    print(f'RMSE for SVR for test {dataset.get(\"name\")}: ', rmse_test)\n",
    "    print(f'R2_score for SVR for test {dataset.get(\"name\")}: ', r2_test)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Определим гиперпараметры для бэггинга"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [300],\n",
    "              'max_samples': [i for i in range(49, 100, 25)],\n",
    "              'estimator__C': [10, 1.2, 7.8],\n",
    "              'estimator__kernel': ['linear']}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация Бэггинга на основе SVR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameters for original_data: {'estimator__C': 10, 'estimator__kernel': 'linear', 'max_samples': 99, 'n_estimators': 300}\n",
      "RMSE for Bagging based on SVR for train original_data:  9.871953146579088\n",
      "R2_score Bagging based on for SVR for train original_data:  0.9845520627278531\n",
      "RMSE for Bagging based on SVR for test original_data:  10.061185524952004\n",
      "R2_score for  Bagging based on SVR for test original_data:  0.9835389286631412\n",
      "\n",
      "Best hyper parameters for original_rescaled_data: {'estimator__C': 10, 'estimator__kernel': 'linear', 'max_samples': 99, 'n_estimators': 300}\n",
      "RMSE for Bagging based on SVR for train original_rescaled_data:  0.04806581372840694\n",
      "R2_score Bagging based on for SVR for train original_rescaled_data:  0.9051771809034665\n",
      "RMSE for Bagging based on SVR for test original_rescaled_data:  0.052831704180885175\n",
      "R2_score for  Bagging based on SVR for test original_rescaled_data:  0.8824764340814361\n",
      "\n",
      "Best hyper parameters for essential_data: {'estimator__C': 10, 'estimator__kernel': 'linear', 'max_samples': 99, 'n_estimators': 300}\n",
      "RMSE for Bagging based on SVR for train essential_data:  27.412588597982865\n",
      "R2_score Bagging based on for SVR for train essential_data:  0.8808855573452721\n",
      "RMSE for Bagging based on SVR for test essential_data:  27.080162454637108\n",
      "R2_score for  Bagging based on SVR for test essential_data:  0.880748922150036\n",
      "\n",
      "Best hyper parameters for rescaled_essential_data: {'estimator__C': 7.8, 'estimator__kernel': 'linear', 'max_samples': 99, 'n_estimators': 300}\n",
      "RMSE for Bagging based on SVR for train rescaled_essential_data:  0.05390534169459293\n",
      "R2_score Bagging based on for SVR for train rescaled_essential_data:  0.8807375103353332\n",
      "RMSE for Bagging based on SVR for test rescaled_essential_data:  0.054125145391549404\n",
      "R2_score for  Bagging based on SVR for test rescaled_essential_data:  0.8766514999736557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    svr_model = SVR()\n",
    "    bagging_model = BaggingRegressor(svr_model)\n",
    "    grid_search = GridSearchCV(bagging_model, param_grid)\n",
    "    grid_search.fit(dataset.get('X_train'), dataset.get('Y_train'))\n",
    "\n",
    "    best_params_for_data = grid_search.best_params_\n",
    "    print(f\"Best hyper parameters for {dataset.get('name')}: {best_params_for_data}\")\n",
    "    svr_model_train_data = SVR(C=best_params_for_data.get('estimator__C'),\n",
    "                               kernel=best_params_for_data.get('estimator__kernel'))\n",
    "\n",
    "    bagging_model_train_data = BaggingRegressor(svr_model_train_data,\n",
    "                                                n_estimators=best_params_for_data.get('n_estimators'),\n",
    "                                                max_samples=best_params_for_data.get('max_samples'))\n",
    "    bagging_model_train_data.fit(dataset.get('X_train'), dataset.get('Y_train'))\n",
    "    train_Y_pred = bagging_model_train_data.predict(dataset.get('X_train'))\n",
    "    rmse_train = np.sqrt(mean_squared_error(dataset.get('Y_train'), train_Y_pred))\n",
    "    r2_train = r2_score(dataset.get('Y_train'), train_Y_pred)\n",
    "    print(f'RMSE for Bagging based on SVR for train {dataset.get(\"name\")}: ', rmse_train)\n",
    "    print(f'R2_score Bagging based on for SVR for train {dataset.get(\"name\")}: ', r2_train)\n",
    "\n",
    "    svr_model_test_data = SVR(C=best_params_for_data.get('estimator__C'),\n",
    "                              kernel=best_params_for_data.get('estimator__kernel'))\n",
    "    bagging_model_test_data = BaggingRegressor(svr_model_test_data,\n",
    "                                                n_estimators=best_params_for_data.get('n_estimators'),\n",
    "                                                max_samples=best_params_for_data.get('max_samples'))\n",
    "    bagging_model_test_data.fit(dataset.get('X_test'), dataset.get('Y_test'))\n",
    "    test_Y_pred = bagging_model_test_data.predict(dataset.get('X_test'))\n",
    "    rmse_test = np.sqrt(mean_squared_error(dataset.get('Y_test'), test_Y_pred))\n",
    "    r2_test = r2_score(dataset.get('Y_test'), test_Y_pred)\n",
    "    print(f'RMSE for Bagging based on SVR for test {dataset.get(\"name\")}: ', rmse_test)\n",
    "    print(f'R2_score for  Bagging based on SVR for test {dataset.get(\"name\")}: ', r2_test)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выводы: Наилучшей предиктивной моделью, найденной в ЛР№1 была полиномиальная регрессия 2 степени, на исходном наборе данных, которая имела на тестовом наборе данных R^2 равное 0.981921257183405. В Лабораторной работе №2 лучшей моделью стала SVC на исходном наборе данных с оценкой на тестовом наборе данных, с R^2 равной 0.9835824211779726, что лучше, чем у полиномиальной регрессии 2 степени, на исходном наборе данных из ЛР№1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
